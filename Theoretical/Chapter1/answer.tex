\documentclass[a4paper]{article}
\usepackage[affil-it]{authblk}
\usepackage[backend=bibtex,style=numeric]{biblatex}

\usepackage{amsmath}
\usepackage{geometry}
\geometry{margin=1.5cm, vmargin={0pt,1cm}}
\setlength{\topmargin}{-1cm}
\setlength{\paperheight}{29.7cm}
\setlength{\textheight}{25.3cm}

\addbibresource{citation.bib}

\begin{document}
% =================================================
\title{Numerical Analysis Homework \# 1}

\author{Yuwei Liang 3230102923
  \thanks{Electronic address: \texttt{liangyuwei631@gmail.com}}}
\affil{(Mathematics and Applied Mathematics 2302), Zhejiang University }

\date{Due time: \today}

\maketitle

% ============================================
\section*{I. The interval in the bisection method}

\subsection*{I-a}

Let the interval length after the $n$-th iteration be $h_n$, with $h_0 = 2$.\\
\hspace*{2em} Then $h_{n+1} = \frac{1}{2}h_n$, so $h_n = \dfrac{1}{2^n}h_0 = \dfrac{1}{2^n}2 = \dfrac{1}{2^{n-1}}$. \\
\hspace*{2em} Therefore, the interval length after the $n$-th iteration is $\dfrac{1}{2^{n-1}}$.

\subsection*{I-b}

Let the midpoint of the interval $[a_n, b_n]$ after the $n$-th iteration be $c_n$, then $c_n = \dfrac{a_n + b_n}{2}$.\\
\hspace*{2em} Then $ |r - c_n| \leq \dfrac{b_n - a_n}{2} = \dfrac{h_n}{2} = \dfrac{1}{2^{n}}$.

\section*{II. Relative error in the bisection method}

After $n$ iterations, the interval length $h_{n+1} = \dfrac{b_0 - a_0}{2^n}$, and the relative error is
\[
E_{rel} = \dfrac{|r - c_n|}{|r|} \leq \dfrac{\dfrac{a_0 - b_0}{2^{n+1}}}{a_0} =  \dfrac{a_0 - b_0}{2^{n+1} a_0}.
\]
\hspace*{2em} When
$
n \geq \dfrac{\log(b_0 - a_0) - \log \epsilon - \log a_0}{\log 2} - 1,
$ we have $E_{rel} \leq \epsilon$.

\section*{III. Newton's method for a polynomial}

\[
p(x) = 4x^3 - 2x^2 + 3 = 0
\]
Taking the derivative,
\[
p'(x) = 12x^2 - 4x
\]
\[
\begin{array}{|c|c|c|c|}
\hline
n & x_n & p(x_n) & p'(x_n) \\
\hline
0 & -1 & -3 & 16 \\
1 & -0.8125 & -2.6816 & 9.8438 \\
2 & -0.5401 & -0.7727 & 6.5685 \\
3 & -0.4224 & -0.1319 & 5.1706 \\
4 & -0.3969 & & \\
\hline
\end{array}
\]

\section*{IV. Newton's method using only the derivative at $x_0$}

\begin{align*}
    x_{n+1} &= x_n - \frac{f(x_n)}{f'(x_0)} \\  
    x_{n+1} - \alpha &= x_n - \alpha - \frac{f(x_n)}{f'(x_0)} \\ 
    x_{n+1} - \alpha &= (x_n - \alpha) \left( 1 - \frac{f(x_n) - f(\alpha)}{f'(x_0)(x - \alpha)} \right)\\
    e_{n+1} &= e_n \left(1 - \frac{f'(\xi_n)}{f'(x_0)} \right)
\end{align*}
where $\xi_n$ depends on $x_n$. Let $s = 1$, and $C = \left(1 - \frac{f'(\xi_n)}{f'(x_0)} \right)$.

\section*{V. The iteration $x_{n+1} = \tan^{-1}x_n$}

(i) If $x_1 = 0$, the conclusion is obvious.\\
(ii) If $x_1 \neq 0$, it is easy to see by induction that $x_n \neq 0$.\\
Let $f(x) = \tan^{-1}x$, then $$|f'(x)| = \left| \frac{1}{1+x^2}\right| < 1.$$ By the Contraction Mapping Principle, the sequence $\{x_n\}$ converges.

\section*{VI. Continued fraction}

Let $\alpha$ be the positive solution of the equation $x^2 + px - 1 = 0$, then we have $\alpha^2 + p\alpha - 1 = 0$.\\
\[
\alpha =  \frac{-p + \sqrt{p^2+4}}{2}.
\]
Notice that
\[
x_{n+2} = \frac{1}{p + \dfrac{1}{p + x_n}}= \frac{p + x_n}{p^2 + px_n + 1}.
\]
\begin{align*}
  x_{n+2} - \alpha &= \frac{p + x_n}{\left(p^2 + px_n + 1\right)} - \alpha \\
  &= \frac{p + x_n - p^2\alpha - px_n\alpha - \alpha}{\left(p^2 + px_n + 1\right)}\\
  &= \frac{p(1 - p\alpha) + x_n - px_n\alpha - \alpha}{\left(p^2 + px_n + 1\right)}\\
  &= \frac{p\alpha^2 + x_n - px_n\alpha - \alpha}{\left(p^2 + px_n + 1\right)}\\
  &= \frac{(x_n - \alpha)(1 - p\alpha)}{\left(p^2 + px_n + 1\right)}.
\end{align*}
Since $1 > 1 - p\alpha = \alpha^2 > 0$, we have $|x_{n+2} - \alpha| < |x_n - \alpha|$.\\
Therefore, the sequence $\{x_1, x_3, x_5, \dots\}$ is monotonically decreasing and bounded below, so it converges to a limit. Let this limit be $x$ (with $x > 0$), then we have
\[
  x = \frac{p + x}{p^2 + px + 1}.
\]
Simplifying,
\[
  x^2 + px - 1 = 0.
\]
Thus, $x = \alpha$. Similarly, the sequence $\{x_2, x_4, x_6, \dots\}$ also converges to $\alpha$.\\
In conclusion, the sequence $\{x_n\}$ converges to $\alpha$.

\section*{VII. $a_0 < 0 < b_0$}

In this case, the relative error may not be a good measure. If the root $r$ is very close to 0, the relative error can be large. In the extreme case where $r = 0$, the relative error cannot be well estimated.

\section*{VIII. Newton's method at a root of multiplicity $k$}

\subsection*{VIII-a}
If the root $\alpha$ is a multiple root, then the sequence $\{x_n\}$ will converge linearly to the root $\alpha$, instead of quadratic convergence.\\
We can calculate $\dfrac{|x_{n+1} - \alpha|}{|x_n - \alpha|}$ to judge: if it tends to 0, it is quadratic convergence; otherwise, it is linear convergence, and $\alpha$ is a multiple root.

\subsection*{VIII-b}
Let $f(x) = (x - \alpha)^k g(x)$, where
\[
g(x)=
\begin{cases}
  \frac{f(x)}{(x-\alpha)^k} &\text{if } x \neq \alpha\\
  \frac{f^{(k)}(\alpha)}{k!} &\text{if } x = \alpha.
\end{cases}
\]
It is easy to see that $g(x)$ is continuous, and
\[
f'(x) = k(x-\alpha)^{k-1}g(x) + (x-\alpha)^kg'(x).
\]
\begin{align*}
  x_{n+1} &= x_n - k\frac{f(x)}{f'(x)}\\
  \implies x_{n+1} - \alpha &= x_n - \alpha - k\frac{(x - \alpha)^k g(x)}{k(x-\alpha)^{k-1}g(x) + (x-\alpha)^kg'(x)}\\
  \implies \frac{x_{n+1} - \alpha}{x_n - \alpha} &= 1 - \frac{kg(x)}{kg(x)+ (x - \alpha)g'(x)}\\
  \implies \frac{x_{n+1} - \alpha}{(x_n - \alpha)^2} &= \frac{g'(x)}{kg(x) + (x - \alpha)g'(x)}\\
  \implies \left|\frac{x_{n+1} - \alpha}{(x_n - \alpha)^2}\right| &\leq \frac{g'(x)}{kg(x)}.
\end{align*}
Since $g(x)$ is continuous, we have $\lim\limits_{x \to \alpha} g(x) = g(\alpha)$. Hence, there exists $\delta_1 > 0$ such that when $|x - \alpha| < \delta_1$, $|g(x) - g(\alpha)| < \dfrac{g(\alpha)}{2}$.\\
Since $f(x) \in C^{k+1}$, $f(x)$ has the expansion at $\alpha$:
\[
f(x) = \frac{f^{(k)}(\alpha)}{k!}(x - \alpha)^k + \frac{f^{(k+1)}(\xi)}{(k+1)!}(x - \alpha)^{k+1},
\]
where $\xi_x$ lies between $x$ and $\alpha$.
\begin{align*}
    g'(\alpha) &= \lim\limits_{x \to \alpha} \frac{g(x) - g(\alpha)}{x - \alpha}\\
    &= \lim\limits_{x \to \alpha} \dfrac{\frac{f(x)}{(x - \alpha)^k} - \frac{f^{(k)}(\alpha)}{k!}}{x - \alpha}\\
    &= \lim\limits_{x \to \alpha} f^{(k+1)}(\xi_x).\\
    &= f^{(k+1)}(\alpha).
\end{align*}
Thus, \( g'(x) \) is bounded at \( \alpha \). Moreover, due to the intermediate value property of derivatives and the continuity of \( g'(x) \) in a neighborhood of \( \alpha \), it follows that \( g'(x) \) is continuous at \( \alpha \). So, there exists $\delta_2 > 0$ such that when $|x - \alpha| < \delta_2$, $|g'(x) - g'(\alpha)| < \dfrac{g'(\alpha)}{2}$.\\
Thus, we have
\[
\left|\frac{x_{n+1} - \alpha}{(x_n - \alpha)^2}\right| \leq \frac{3g'(\alpha)}{kg(\alpha)},
\]
which shows that $\{x_n\}$ converges quadratically.

% ===============================================

\end{document}
